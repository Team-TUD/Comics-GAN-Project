{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HumorDetection_Fixed_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DN7GVngv1Nrq"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN7GVngv1Nrq"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJnBgMbkC-f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67e80ed-18a0-499f-8c1c-fa54b9524b48"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6oUnrZBDGXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64659cb-4e62-4dd3-ea6b-8aca2965715f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qnjZ433DHzN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import torch\n",
        "import transformers\n",
        "import seaborn as sns\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xXUqd0R1XMW"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glb0r6-EDJQb"
      },
      "source": [
        "def to_bool(col):\n",
        "  for i in range(len(col)):\n",
        "    if col[i] == 'True':\n",
        "      col[i] = True\n",
        "    elif col[i] == 'False':\n",
        "      col[i] = False\n",
        "  return col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz4UC1NBDL6n"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dev/f_correct_training.csv', names=['text', 'humor'])\n",
        "df['humor'] = to_bool(np.asanyarray(df['humor']))\n",
        "df['humor'] = df['humor'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1JTG5g-DNgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4880963-00b4-4470-c326-6adc4f209d98"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = np.random.randint(0, 1000)\n",
        "print('random seed: ', RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.25, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.7, random_state=RANDOM_SEED)\n",
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random seed:  918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1001, 2), (100, 2), (234, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kun5W6LQ1eVx"
      },
      "source": [
        "# Model Creation & Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC6DCWrnDTOv"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwwsc-g-1tOd"
      },
      "source": [
        "## The Dataset for humor detection\n",
        "\n",
        "*  All the tokens are padded to MAX_LEN value\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0mv8oF5Dali"
      },
      "source": [
        "class HumorDetectionDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, texts, labels, tokenizer, max_length, batch_size):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_length\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    text = str(self.texts[item])\n",
        "    label = self.labels[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=self.max_len,\n",
        "        return_token_type_ids=False,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'text' : text,\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "        'labels' : torch.tensor(label, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FY7w-_x18ID"
      },
      "source": [
        "## The DataLoader for the HumorDetection dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD85HhytDefF"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_data_loader(df, tokenizer, max_length, batch_size):\n",
        "  ds = HumorDetectionDataset(\n",
        "      texts=df.text.to_numpy(),\n",
        "      labels=df.humor.to_numpy(),\n",
        "      tokenizer=tokenizer,\n",
        "      max_length=max_length,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "      ds,\n",
        "      batch_size=batch_size,\n",
        "      num_workers=2\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mklGlVCdDgH6"
      },
      "source": [
        "MAX_LEN = 50\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaZJzeW12D0M"
      },
      "source": [
        "## The classifier consists of a:\n",
        "\n",
        "*   Pre-Trained BERT Model\n",
        "*   Dropout Layer (*p=0.1*)\n",
        "*   Fully Connected Layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI0iJOsyDjVA"
      },
      "source": [
        "class HumorClassifier(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(HumorClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = torch.nn.Dropout(p=0.1)\n",
        "    self.out = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    returned = self.bert(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "    )\n",
        "    pooled_output = returned.pooler_output\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxPCVY2kDnm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d678c8-0c46-4939-8ffa-e63dd108d85d"
      },
      "source": [
        "model = HumorClassifier(2)\n",
        "device = torch.device(type='cuda', index=0)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC0Dsntw2cL3"
      },
      "source": [
        "## Initialization of parameters for the model and training\n",
        "\n",
        "*  Learning rate = 2e-5\n",
        "*  Bias correction = True\n",
        "*  Weight decay = 0.01\n",
        "*  warmup = 10% of total steps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKbzSbvYDyhs"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "EPOCHS = 6\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5,\n",
        "                  eps = 1e-6,\n",
        "                  correct_bias=True,\n",
        "                  weight_decay=0.01)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=warmup_steps,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = CrossEntropyLoss().to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8fvQiMiD1H2"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for batch in data_loader:\n",
        "    b_input_ids = batch['input_ids'].to(device)\n",
        "    b_att_mask = batch['attention_mask'].to(device)\n",
        "    b_labels = batch['labels'].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model(b_input_ids, b_att_mask)\n",
        "\n",
        "    _, preds = torch.max(logits, dim=1)\n",
        "    loss = loss_fn(logits, b_labels)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == b_labels)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dxJyWTAD3PD"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      b_input_ids = batch['input_ids'].to(device)\n",
        "      b_att_mask = batch['attention_mask'].to(device)\n",
        "      b_labels = batch['labels'].to(device)\n",
        "\n",
        "      logits = model(b_input_ids, b_att_mask)\n",
        "\n",
        "      _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "      loss = loss_fn(logits, b_labels)\n",
        "      \n",
        "      losses.append(loss.item())\n",
        "      correct_predictions += torch.sum(preds == b_labels)\n",
        "      \n",
        "  print('Final preds: ', correct_predictions.double())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLfGUERo3q75"
      },
      "source": [
        "def predict_labels(model, data_loader):\n",
        "  \n",
        "  predicted_labels = []\n",
        "  real_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "\n",
        "      b_input_ids = batch['input_ids'].to(device)\n",
        "      b_att_mask = batch['attention_mask'].to(device)\n",
        "      b_labels = batch['labels'].to(device)\n",
        "\n",
        "      logits = model(b_input_ids, b_att_mask)\n",
        "\n",
        "      _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "      probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "      predicted_labels.extend(preds)\n",
        "      real_labels.extend(b_labels)\n",
        "  \n",
        "  predicted_labels = torch.stack(predicted_labels).cpu()\n",
        "  real_labels = torch.stack(real_labels).cpu()\n",
        "  return real_labels, predicted_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6e1Bja22tWE"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvMaceADHWwX",
        "outputId": "fbeac751-6081-45f4-b178-619a93efda1f"
      },
      "source": [
        "%%time\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('-' * 20)\n",
        "  print('Epoch: ', epoch+1)\n",
        "  print('-' * 20)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model,\n",
        "                                      train_data_loader,\n",
        "                                      loss_fn,\n",
        "                                      optimizer,\n",
        "                                      device,\n",
        "                                      scheduler,\n",
        "                                      len(df_train))\n",
        "  \n",
        "  print('Train loss: ', train_loss)\n",
        "  print('Train acc: ', train_acc.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch:  1\n",
            "--------------------\n",
            "Train loss:  0.6745135576005966\n",
            "Train acc:  0.6033966033966034\n",
            "--------------------\n",
            "Epoch:  2\n",
            "--------------------\n",
            "Train loss:  0.4975763942514147\n",
            "Train acc:  0.7832167832167832\n",
            "--------------------\n",
            "Epoch:  3\n",
            "--------------------\n",
            "Train loss:  0.32147454955275095\n",
            "Train acc:  0.8841158841158842\n",
            "--------------------\n",
            "Epoch:  4\n",
            "--------------------\n",
            "Train loss:  0.17788400205354843\n",
            "Train acc:  0.949050949050949\n",
            "--------------------\n",
            "Epoch:  5\n",
            "--------------------\n",
            "Train loss:  0.12058858339866949\n",
            "Train acc:  0.968031968031968\n",
            "--------------------\n",
            "Epoch:  6\n",
            "--------------------\n",
            "Train loss:  0.09693766955936713\n",
            "Train acc:  0.973026973026973\n",
            "CPU times: user 1min 5s, sys: 2.38 s, total: 1min 7s\n",
            "Wall time: 1min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yFP6Jqi2u_E"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-sYY92SIG2v",
        "outputId": "6fb90154-f716-4f57-847c-889db09d3481"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final preds:  tensor(183., device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7820512820512822"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLbBBe-d2zbB",
        "outputId": "409ede13-9357-4df3-8fc9-24ee9b8d3241"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
        "\n",
        "real_labels, predicted_labels = predict_labels(model, test_data_loader)\n",
        "\n",
        "f1 = f1_score(real_labels, predicted_labels)\n",
        "prec_rec_f1 = precision_recall_fscore_support(real_labels, predicted_labels, average='binary')\n",
        "\n",
        "print('F1-Score: ', f1)\n",
        "print(prec_rec_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score:  0.7999999999999999\n",
            "(0.8360655737704918, 0.7669172932330827, 0.7999999999999999, None)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}