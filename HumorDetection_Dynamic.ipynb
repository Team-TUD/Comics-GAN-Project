{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HumorDetection_Dynamic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMaco5Qp226L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-P67tQatsl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04284776-0618-48d7-f8de-563bc0270577"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db1OTRT7k6FY",
        "outputId": "7765e96b-c0fd-43a1-ec9c-82437ddc7e58"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS7925Ket56B"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import torch\n",
        "import transformers\n",
        "import seaborn as sns\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga2g6TFM27ml"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN0wNpDu4Ub_"
      },
      "source": [
        "## Loading the dataset and splitting the data into a train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKF2wTTUuE7Z"
      },
      "source": [
        "def to_bool(col):\n",
        "  for i in range(len(col)):\n",
        "    if col[i] == 1:\n",
        "      col[i] = True\n",
        "    else:\n",
        "      col[i] = False\n",
        "  return col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6R6FLpWuIC_"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dev/f_correct_training.csv', names=['text', 'humor'])\n",
        "df['humor'] = to_bool(np.asanyarray(df['humor']))\n",
        "df['humor'] = df['humor'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQu7uDMVuQeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b34026b-85b4-445e-95da-b4c1f597bb8c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = np.random.randint(0, 1000)\n",
        "print('random seed: ', RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.25, random_state=RANDOM_SEED)\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random seed:  99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1001, 2), (334, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuIdP3dcugHt"
      },
      "source": [
        "train_text = []\n",
        "train_labels = []\n",
        "\n",
        "for txt in df_train.text:\n",
        "    train_text.append(txt)\n",
        "for lbl in df_train.humor:\n",
        "    train_labels.append(lbl)\n",
        "\n",
        "test_text = []\n",
        "test_labels = []\n",
        "\n",
        "for txt in df_test.text:\n",
        "    test_text.append(txt)\n",
        "for lbl in df_test.humor:\n",
        "    test_labels.append(lbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsQeYYik3ALg"
      },
      "source": [
        "# Model Creation & Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39-T4Yp14f3U"
      },
      "source": [
        "## The classifier consists of a:\n",
        "\n",
        "*   Pre-Trained BERT Model\n",
        "*   Dropout Layer (*p=0.1*)\n",
        "*   Fully Connected Layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWTJdJ2muwqR"
      },
      "source": [
        "class HumorClassifier(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(HumorClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = torch.nn.Dropout(p=0.1)\n",
        "    self.out = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    returned = self.bert(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "    )\n",
        "    pooled_output = returned.pooler_output\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pD1rK5Nuyla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7277ca35-2f7f-44d9-9346-cda300439e22"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME) \n",
        "model = HumorClassifier(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bePpChI7u2e-"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flsS-uiV6PuS"
      },
      "source": [
        "## Initialization of parameters for the model and training\n",
        "\n",
        "*  Max length of the padded input = 50\n",
        "*  Batch size = 16\n",
        "*  Learning rate = 2e-5\n",
        "*  Bias correction = True\n",
        "*  Weight decay = 0.01\n",
        "*  warmup = 10% of total steps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqthhFe4u6G0"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.nn import CrossEntropyLoss, NLLLoss, BCEWithLogitsLoss\n",
        "\n",
        "MAX_LEN = 50\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 6\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # This is the value Michael used.\n",
        "                  eps = 1e-6, # args.adam_epsilon  - default is 1e-8.\n",
        "                  correct_bias=True,\n",
        "                  weight_decay=0.01\n",
        "                )\n",
        "\n",
        "total_steps = len(train_text) * EPOCHS\n",
        "warmup_steps = 0.1 * total_steps\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "\n",
        "loss_fn = CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vKZvlqv609M"
      },
      "source": [
        "## Helper function for creating training batches according with the *dynamic approach*\n",
        "\n",
        "1. The analyzed text is sorted by length. \n",
        "2. A number of examples are selected from a random point in the sorted array and put together as one batch.\n",
        "3. Inputs within a batch are padded to the length of the longes input sequence in that batch.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvmGkKUTeBCK"
      },
      "source": [
        "def dynamic_batching(all_text, all_labels, batch_size):\n",
        "\n",
        "  all_input_ids = []\n",
        "  \n",
        "  print('Tokenizing Text...')\n",
        "\n",
        "  for txt in all_text:\n",
        "\n",
        "    input_id = tokenizer.encode(text=txt,\n",
        "                                add_special_tokens=True,\n",
        "                                max_length=MAX_LEN,\n",
        "                                truncation=True,\n",
        "                                padding=False)\n",
        "    all_input_ids.append(input_id)\n",
        "  \n",
        "\n",
        "  samples = sorted(zip(all_input_ids, all_labels), key=lambda x: len(x[0]))\n",
        "\n",
        "  text_batches = []\n",
        "  labels_batches = []\n",
        "\n",
        "  print('Selecting Batches...')\n",
        "\n",
        "  while len(samples) > 0:\n",
        "    to_take = min(batch_size, len(samples))\n",
        "    idx = random.randint(0, len(samples) - to_take)\n",
        "\n",
        "    batch = samples[idx : (idx + to_take)]\n",
        "\n",
        "    text_batches.append([x[0] for x in batch])\n",
        "    labels_batches.append([x[1] for x in batch])\n",
        "\n",
        "    del samples[idx : idx + to_take]\n",
        "  \n",
        "\n",
        "  final_input_ids = []\n",
        "  final_att_masks = []\n",
        "  final_labels = []\n",
        "\n",
        "  batched_input = zip(text_batches, labels_batches) \n",
        "\n",
        "  print('Padding...')\n",
        "\n",
        "  for (texts, labels) in batched_input:\n",
        "\n",
        "    batch_padded_input_ids = []\n",
        "    batch_att_masks = []\n",
        "\n",
        "    max_size = max([len(txt) for txt in texts])\n",
        "\n",
        "    for txt in texts:\n",
        "      num_pad_tokens = max_size - len(txt)\n",
        "      padded_text = txt + [tokenizer.pad_token_id] * num_pad_tokens\n",
        "      att_mask = [1] * len(txt) + [0] * num_pad_tokens\n",
        "\n",
        "      batch_padded_input_ids.append(padded_text)\n",
        "      batch_att_masks.append(att_mask)\n",
        "    \n",
        "    final_input_ids.append(torch.tensor(batch_padded_input_ids))\n",
        "    final_att_masks.append(torch.tensor(batch_att_masks))\n",
        "    final_labels.append(torch.tensor(labels))\n",
        "  \n",
        "  print('Batches Created')\n",
        "  return(final_input_ids, final_att_masks, final_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dntia62M3F5D"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B42My_3ZtaRa",
        "outputId": "adca91fc-3a7d-4764-8efe-c8097996d79f"
      },
      "source": [
        "%%time\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "  print('-' * 20)\n",
        "  print('Epoch: ', epoch+1)\n",
        "  print('-' * 20)\n",
        "\n",
        "  print('Creating training batches...')\n",
        "\n",
        "  (input_ids, att_masks, labels) = dynamic_batching(train_text, train_labels, BATCH_SIZE)\n",
        "  print('-' * 15)\n",
        "  print('Trainiing on: ', len(input_ids), ' batches')\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in range(0, len(input_ids)):\n",
        "\n",
        "    b_input_ids = input_ids[batch].to(device)\n",
        "    b_att_mask = att_masks[batch].to(device)\n",
        "    b_labels = labels[batch].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model(b_input_ids, b_att_mask)\n",
        "\n",
        "    _, preds = torch.max(logits, dim=1)\n",
        "    loss = loss_fn(logits, b_labels)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == b_labels).item()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "  avg_train_loss = np.sum(losses) / len(input_ids)\n",
        "  accuracy = correct_predictions / len(train_text) \n",
        "  print('avg training loss: ', avg_train_loss)\n",
        "  print('accuracy: ', accuracy)\n",
        "\n",
        "print('training done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Epoch:  1\n",
            "--------------------\n",
            "Creating training batches...\n",
            "Tokenizing Text...\n",
            "Selecting Batches...\n",
            "Padding...\n",
            "Batches Created\n",
            "---------------\n",
            "Trainiing on:  63  batches\n",
            "avg training loss:  0.6914909264397999\n",
            "accuracy:  0.5564435564435565\n",
            "--------------------\n",
            "Epoch:  2\n",
            "--------------------\n",
            "Creating training batches...\n",
            "Tokenizing Text...\n",
            "Selecting Batches...\n",
            "Padding...\n",
            "Batches Created\n",
            "---------------\n",
            "Trainiing on:  63  batches\n",
            "avg training loss:  0.6875141792827182\n",
            "accuracy:  0.5554445554445554\n",
            "--------------------\n",
            "Epoch:  3\n",
            "--------------------\n",
            "Creating training batches...\n",
            "Tokenizing Text...\n",
            "Selecting Batches...\n",
            "Padding...\n",
            "Batches Created\n",
            "---------------\n",
            "Trainiing on:  63  batches\n",
            "avg training loss:  0.667988291808537\n",
            "accuracy:  0.5924075924075924\n",
            "--------------------\n",
            "Epoch:  4\n",
            "--------------------\n",
            "Creating training batches...\n",
            "Tokenizing Text...\n",
            "Selecting Batches...\n",
            "Padding...\n",
            "Batches Created\n",
            "---------------\n",
            "Trainiing on:  63  batches\n",
            "avg training loss:  0.6189566779704321\n",
            "accuracy:  0.6523476523476524\n",
            "--------------------\n",
            "Epoch:  5\n",
            "--------------------\n",
            "Creating training batches...\n",
            "Tokenizing Text...\n",
            "Selecting Batches...\n",
            "Padding...\n",
            "Batches Created\n",
            "---------------\n",
            "Trainiing on:  63  batches\n",
            "avg training loss:  0.4578504746868497\n",
            "accuracy:  0.7812187812187812\n",
            "--------------------\n",
            "Epoch:  6\n",
            "--------------------\n",
            "Creating training batches...\n",
            "Tokenizing Text...\n",
            "Selecting Batches...\n",
            "Padding...\n",
            "Batches Created\n",
            "---------------\n",
            "Trainiing on:  63  batches\n",
            "avg training loss:  0.24942610069872842\n",
            "accuracy:  0.9050949050949051\n",
            "training done!\n",
            "CPU times: user 39.6 s, sys: 2.12 s, total: 41.8 s\n",
            "Wall time: 41.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pemn3FnW3IM_"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPFsXhYNjlIb",
        "outputId": "895363e9-cb37-42a8-8f1d-b6e15a08beb4"
      },
      "source": [
        "test_inputs, test_att_masks, test_labels = dynamic_batching(test_text, test_labels, BATCH_SIZE)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "print('Test Set Predictions...')\n",
        "\n",
        "for batch in range(0, len(test_inputs)):\n",
        "\n",
        "  b_input_ids = test_inputs[batch].to(device)\n",
        "  b_att_mask = test_att_masks[batch].to(device)\n",
        "  b_labels = test_labels[batch].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    logits = model(b_input_ids, b_att_mask)\n",
        "  \n",
        "  logits = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Evaluation Done!')\n",
        "\n",
        "print('-' * 20)\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "preds = np.argmax(predictions, axis=1).flatten()\n",
        "print('Accuracy:')\n",
        "print(np.sum(preds == true_labels) / len(true_labels))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing Text...\n",
            "Selecting Batches...\n",
            "Padding...\n",
            "Batches Created\n",
            "Test Set Predictions...\n",
            "Evaluation Done!\n",
            "--------------------\n",
            "Accuracy:\n",
            "0.7934131736526946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuCvghrFCPS",
        "outputId": "1cd54d48-f848-405a-fd19-125020297fbd"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
        "\n",
        "f1 = f1_score(true_labels, preds)\n",
        "prec_rec_f1 = precision_recall_fscore_support(true_labels, preds, average='binary')\n",
        "\n",
        "print('F1-Score: ', f1)\n",
        "print(prec_rec_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score:  0.8217054263565892\n",
            "(0.8548387096774194, 0.7910447761194029, 0.8217054263565892, None)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}